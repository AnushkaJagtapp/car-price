{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5beb62d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created car_price.csv with 5000 records\n",
      "Price range: $3,000.00 to $106,048.11\n",
      "Average price: $43,078.93\n",
      "\n",
      "Sample data:\n",
      "   car_id      brand    model  year  mileage  engine_size fuel_type  \\\n",
      "0       1      Volvo    Truck  2008    27807          1.6    Hybrid   \n",
      "1       2       Audi  Minivan  2003   109965          1.9    Petrol   \n",
      "2       3  Chevrolet  Minivan  2018    93289          2.1    Hybrid   \n",
      "3       4    Hyundai  Minivan  2023    37267          3.8    Diesel   \n",
      "4       5      Honda    Coupe  2013    58802          4.9    Petrol   \n",
      "\n",
      "  transmission  owner_count  accident_history service_history   color  \\\n",
      "0    Automatic            2                 0            None    Gray   \n",
      "1    Automatic            3                 0         Partial  Silver   \n",
      "2          CVT            0                 0         Partial    Blue   \n",
      "3       Manual            3                 0            Full   Black   \n",
      "4    Automatic            1                 0         Partial   Green   \n",
      "\n",
      "      price  \n",
      "0  36103.95  \n",
      "1  30057.14  \n",
      "2  37595.69  \n",
      "3  36557.65  \n",
      "4  22923.95  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create synthetic car data\n",
    "n_samples = 5000\n",
    "\n",
    "# Car brands with different price tiers\n",
    "brands_tier1 = ['Tesla', 'Mercedes', 'BMW', 'Audi', 'Porsche']\n",
    "brands_tier2 = ['Lexus', 'Volvo', 'Jaguar', 'Land Rover']\n",
    "brands_tier3 = ['Toyota', 'Honda', 'Ford', 'Chevrolet', 'Nissan', 'Hyundai', 'Kia']\n",
    "all_brands = brands_tier1 + brands_tier2 + brands_tier3\n",
    "\n",
    "# Generate data\n",
    "data = {\n",
    "    'car_id': range(1, n_samples + 1),\n",
    "    'brand': np.random.choice(all_brands, n_samples),\n",
    "    'model': np.random.choice(['Sedan', 'SUV', 'Truck', 'Coupe', 'Convertible', 'Hatchback', 'Minivan'], n_samples),\n",
    "    'year': np.random.randint(2000, 2024, n_samples),\n",
    "    'mileage': np.random.exponential(50000, n_samples).astype(int),\n",
    "    'engine_size': np.round(np.random.uniform(1.0, 6.0, n_samples), 1),\n",
    "    'fuel_type': np.random.choice(['Petrol', 'Diesel', 'Hybrid', 'Electric'], n_samples, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "    'transmission': np.random.choice(['Automatic', 'Manual', 'CVT'], n_samples, p=[0.7, 0.25, 0.05]),\n",
    "    'owner_count': np.random.randint(0, 6, n_samples),\n",
    "    'accident_history': np.random.choice([0, 1], n_samples, p=[0.85, 0.15]),\n",
    "    'service_history': np.random.choice(['Full', 'Partial', 'None'], n_samples, p=[0.6, 0.3, 0.1]),\n",
    "    'color': np.random.choice(['Black', 'White', 'Silver', 'Gray', 'Red', 'Blue', 'Green'], n_samples),\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate base price based on features\n",
    "base_price = 20000\n",
    "\n",
    "# Adjust price based on brand tier\n",
    "def get_brand_multiplier(brand):\n",
    "    if brand in brands_tier1:\n",
    "        return 2.5\n",
    "    elif brand in brands_tier2:\n",
    "        return 1.8\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "# Adjust price based on model type\n",
    "def get_model_multiplier(model):\n",
    "    multipliers = {\n",
    "        'SUV': 1.3,\n",
    "        'Truck': 1.2,\n",
    "        'Coupe': 1.1,\n",
    "        'Convertible': 1.4,\n",
    "        'Sedan': 1.0,\n",
    "        'Hatchback': 0.9,\n",
    "        'Minivan': 0.95\n",
    "    }\n",
    "    return multipliers.get(model, 1.0)\n",
    "\n",
    "# Calculate price for each car\n",
    "prices = []\n",
    "for i in range(n_samples):\n",
    "    price = base_price\n",
    "    \n",
    "    # Brand multiplier\n",
    "    brand_mult = get_brand_multiplier(df.loc[i, 'brand'])\n",
    "    price *= brand_mult\n",
    "    \n",
    "    # Model multiplier\n",
    "    model_mult = get_model_multiplier(df.loc[i, 'model'])\n",
    "    price *= model_mult\n",
    "    \n",
    "    # Year effect ($1000 per year from 2000)\n",
    "    year_effect = (df.loc[i, 'year'] - 2000) * 800\n",
    "    price += year_effect\n",
    "    \n",
    "    # Mileage effect (-$0.08 per mile)\n",
    "    mileage_effect = -df.loc[i, 'mileage'] * 0.08\n",
    "    price += mileage_effect\n",
    "    \n",
    "    # Engine size effect (+$1500 per liter)\n",
    "    engine_effect = df.loc[i, 'engine_size'] * 1500\n",
    "    price += engine_effect\n",
    "    \n",
    "    # Fuel type premium\n",
    "    if df.loc[i, 'fuel_type'] == 'Electric':\n",
    "        price += 15000\n",
    "    elif df.loc[i, 'fuel_type'] == 'Hybrid':\n",
    "        price += 8000\n",
    "    elif df.loc[i, 'fuel_type'] == 'Diesel':\n",
    "        price += 3000\n",
    "    \n",
    "    # Transmission effect\n",
    "    if df.loc[i, 'transmission'] == 'Manual':\n",
    "        price -= 2000\n",
    "    elif df.loc[i, 'transmission'] == 'CVT':\n",
    "        price += 1000\n",
    "    \n",
    "    # Owner count effect (-$1500 per owner)\n",
    "    owner_effect = -df.loc[i, 'owner_count'] * 1500\n",
    "    price += owner_effect\n",
    "    \n",
    "    # Accident history effect (-35% if accident)\n",
    "    if df.loc[i, 'accident_history'] == 1:\n",
    "        price *= 0.65\n",
    "    \n",
    "    # Service history effect\n",
    "    if df.loc[i, 'service_history'] == 'Partial':\n",
    "        price *= 0.9\n",
    "    elif df.loc[i, 'service_history'] == 'None':\n",
    "        price *= 0.7\n",
    "    \n",
    "    # Add some randomness\n",
    "    price += np.random.normal(0, 5000)\n",
    "    \n",
    "    # Ensure minimum price\n",
    "    price = max(price, 3000)\n",
    "    \n",
    "    prices.append(price)\n",
    "\n",
    "# Add price column\n",
    "df['price'] = np.round(prices, 2)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('car_price.csv', index=False)\n",
    "print(f\"Created car_price.csv with {n_samples} records\")\n",
    "print(f\"Price range: ${df['price'].min():,.2f} to ${df['price'].max():,.2f}\")\n",
    "print(f\"Average price: ${df['price'].mean():,.2f}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ed2674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Dataset shape: (5000, 11)\n",
      "Features: ['brand', 'model', 'year', 'mileage', 'engine_size', 'fuel_type', 'transmission', 'owner_count', 'accident_history', 'service_history']\n",
      "Target: price\n",
      "\n",
      "Creating model pipeline...\n",
      "Splitting data...\n",
      "Training set: (4000, 10)\n",
      "Test set: (1000, 10)\n",
      "\n",
      "Training model...\n",
      "Making predictions...\n",
      "\n",
      "============================================================\n",
      "MODEL PERFORMANCE METRICS\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "MAE:  $3,542.50\n",
      "MSE:  $20,242,790.97\n",
      "RMSE: $4,499.20\n",
      "R²:   0.9422\n",
      "\n",
      "Test Set:\n",
      "MAE:  $4,824.99\n",
      "MSE:  $36,035,791.24\n",
      "RMSE: $6,002.98\n",
      "R²:   0.8995\n",
      "\n",
      "Cross-validation scores (5-fold):\n",
      "R² scores: [0.90440984 0.89729712 0.89166278 0.90031385 0.90575976]\n",
      "Mean R²: 0.8999 (+/- 0.0102)\n",
      "\n",
      "Extracting feature information...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 120\u001b[0m\n\u001b[0;32m    113\u001b[0m all_feature_names \u001b[38;5;241m=\u001b[39m numerical_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(cat_feature_names)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Prepare preprocessing information\u001b[39;00m\n\u001b[0;32m    116\u001b[0m feature_info \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_features\u001b[39m\u001b[38;5;124m'\u001b[39m: categorical_features,\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerical_features\u001b[39m\u001b[38;5;124m'\u001b[39m: numerical_features,\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_features\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns),\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformed_features\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mall_feature_names\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m(),\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_categories\u001b[39m\u001b[38;5;124m'\u001b[39m: {},\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerical_stats\u001b[39m\u001b[38;5;124m'\u001b[39m: {},\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_stats\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(y\u001b[38;5;241m.\u001b[39mmin()),\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(y\u001b[38;5;241m.\u001b[39mmax()),\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(y\u001b[38;5;241m.\u001b[39mmean()),\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(y\u001b[38;5;241m.\u001b[39mstd())\n\u001b[0;32m    128\u001b[0m     }\n\u001b[0;32m    129\u001b[0m }\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Add categorical categories\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m categorical_features:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('car_price.csv')\n",
    "\n",
    "# Remove car_id and color columns as they're not useful for prediction\n",
    "df = df.drop(['car_id', 'color'], axis=1)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {list(df.columns[:-1])}\")\n",
    "print(f\"Target: price\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['brand', 'model', 'fuel_type', 'transmission', 'service_history']\n",
    "numerical_features = ['year', 'mileage', 'engine_size', 'owner_count', 'accident_history']\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the model pipeline\n",
    "print(\"\\nCreating model pipeline...\")\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        subsample=0.8,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_iter_no_change=10,\n",
    "        validation_fraction=0.1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Split data\n",
    "print(\"Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nTraining model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "print(\"Making predictions...\")\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining Set:\")\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"MAE:  ${train_mae:,.2f}\")\n",
    "print(f\"MSE:  ${train_mse:,.2f}\")\n",
    "print(f\"RMSE: ${train_rmse:,.2f}\")\n",
    "print(f\"R²:   {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"MAE:  ${test_mae:,.2f}\")\n",
    "print(f\"MSE:  ${test_mse:,.2f}\")\n",
    "print(f\"RMSE: ${test_rmse:,.2f}\")\n",
    "print(f\"R²:   {test_r2:.4f}\")\n",
    "\n",
    "# Cross-validation\n",
    "print(\"\\nCross-validation scores (5-fold):\")\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"R² scores: {cv_scores}\")\n",
    "print(f\"Mean R²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Get feature names after one-hot encoding\n",
    "print(\"\\nExtracting feature information...\")\n",
    "preprocessor.fit(X)\n",
    "cat_encoder = preprocessor.named_transformers_['cat']\n",
    "cat_feature_names = cat_encoder.get_feature_names_out(categorical_features)\n",
    "all_feature_names = numerical_features + list(cat_feature_names)\n",
    "\n",
    "# Prepare preprocessing information\n",
    "feature_info = {\n",
    "    'categorical_features': categorical_features,\n",
    "    'numerical_features': numerical_features,\n",
    "    'all_features': list(X.columns),\n",
    "    'transformed_features': all_feature_names.tolist(),\n",
    "    'categorical_categories': {},\n",
    "    'numerical_stats': {},\n",
    "    'price_stats': {\n",
    "        'min': float(y.min()),\n",
    "        'max': float(y.max()),\n",
    "        'mean': float(y.mean()),\n",
    "        'std': float(y.std())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add categorical categories\n",
    "for feature in categorical_features:\n",
    "    unique_values = X[feature].unique().tolist()\n",
    "    feature_info['categorical_categories'][feature] = unique_values\n",
    "\n",
    "# Add numerical statistics\n",
    "for feature in numerical_features:\n",
    "    stats = {\n",
    "        'min': float(X[feature].min()),\n",
    "        'max': float(X[feature].max()),\n",
    "        'mean': float(X[feature].mean()),\n",
    "        'std': float(X[feature].std())\n",
    "    }\n",
    "    feature_info['numerical_stats'][feature] = stats\n",
    "\n",
    "# Add model metadata\n",
    "feature_info['model_metadata'] = {\n",
    "    'model_type': 'GradientBoostingRegressor',\n",
    "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'performance': {\n",
    "        'train_r2': float(train_r2),\n",
    "        'test_r2': float(test_r2),\n",
    "        'train_mae': float(train_mae),\n",
    "        'test_mae': float(test_mae),\n",
    "        'train_rmse': float(train_rmse),\n",
    "        'test_rmse': float(test_rmse)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the model\n",
    "print(\"\\nSaving model and preprocessing files...\")\n",
    "import os\n",
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = 'model/car_price_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"✓ Model saved to {model_path}\")\n",
    "\n",
    "# Save preprocessing info\n",
    "preprocessing_path = 'model/preprocessing.pkl'\n",
    "joblib.dump(feature_info, preprocessing_path)\n",
    "print(f\"✓ Preprocessing info saved to {preprocessing_path}\")\n",
    "\n",
    "# Also save as JSON for easy reading\n",
    "json_path = 'model/preprocessing_info.json'\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2, default=str)\n",
    "print(f\"✓ JSON info saved to {json_path}\")\n",
    "\n",
    "# Test the saved model\n",
    "print(\"\\nTesting saved model...\")\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_info = joblib.load(preprocessing_path)\n",
    "\n",
    "# Create a test sample\n",
    "test_sample = pd.DataFrame({\n",
    "    'brand': ['Toyota'],\n",
    "    'model': ['SUV'],\n",
    "    'year': [2020],\n",
    "    'mileage': [30000],\n",
    "    'engine_size': [2.5],\n",
    "    'fuel_type': ['Hybrid'],\n",
    "    'transmission': ['Automatic'],\n",
    "    'owner_count': [1],\n",
    "    'accident_history': [0],\n",
    "    'service_history': ['Full']\n",
    "})\n",
    "\n",
    "# Make prediction\n",
    "prediction = loaded_model.predict(test_sample)[0]\n",
    "print(f\"\\nTest prediction for sample car:\")\n",
    "print(f\"Features: 2020 Toyota SUV, 30,000 miles, Hybrid, 1 owner, no accidents\")\n",
    "print(f\"Predicted price: ${prediction:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"- Dataset size: {len(df)} cars\")\n",
    "print(f\"- Features used: {len(feature_info['all_features'])}\")\n",
    "print(f\"- Model R² score: {test_r2:.4f}\")\n",
    "print(f\"- Average error: ${test_mae:,.2f}\")\n",
    "print(f\"- Price range in dataset: ${feature_info['price_stats']['min']:,.2f} to ${feature_info['price_stats']['max']:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6536484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CAR PRICE PREDICTION PROJECT - FILE GENERATOR\n",
      "============================================================\n",
      "Creating car_price.csv...\n",
      "✓ Created car_price.csv with 5000 records\n",
      "  Price range: $3,000.00 to $106,048.11\n",
      "\n",
      "Creating model files...\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.create_dummy_model_files.<locals>.DummyCarPriceModel'>: it's not found as __main__.create_dummy_model_files.<locals>.DummyCarPriceModel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 298\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Created train_model.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 298\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 215\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    212\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# Create dummy model files for immediate use\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m \u001b[43mcreate_dummy_model_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Create a simple train_model.py that users can run\u001b[39;00m\n\u001b[0;32m    218\u001b[0m create_train_script()\n",
      "Cell \u001b[1;32mIn[3], line 195\u001b[0m, in \u001b[0;36mcreate_dummy_model_files\u001b[1;34m()\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Create and save dummy model\u001b[39;00m\n\u001b[0;32m    189\u001b[0m dummy_model \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: DummyCarPriceModel(),\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_fitted\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    193\u001b[0m }\n\u001b[1;32m--> 195\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel/car_price_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Created dummy model files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️  Note: These are placeholder files. Run train_model.py for actual trained model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:553\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 553\u001b[0m         \u001b[43mNumpyPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    555\u001b[0m     NumpyPickler(filename, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mend_framing()\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\pickle.py:972\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m DICT)\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 972\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\pickle.py:998\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[0;32m    997\u001b[0m         save(k)\n\u001b[1;32m--> 998\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    999\u001b[0m     write(SETITEMS)\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\pickle.py:687\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs[0] from __newobj__ args has the wrong class\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    686\u001b[0m args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 687\u001b[0m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m save(args)\n\u001b[0;32m    689\u001b[0m write(NEWOBJ)\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\pickle.py:1129\u001b[0m, in \u001b[0;36m_Pickler.save_type\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m):\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(\u001b[38;5;28mtype\u001b[39m, (\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,), obj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[1;32m-> 1129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_global\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\Desktop\\data science\\venv\\lib\\pickle.py:1071\u001b[0m, in \u001b[0;36m_Pickler.save_global\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     obj2, parent \u001b[38;5;241m=\u001b[39m _getattribute(module, name)\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\n\u001b[0;32m   1072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m: it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms not found as \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1073\u001b[0m         (obj, module_name, name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj:\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class '__main__.create_dummy_model_files.<locals>.DummyCarPriceModel'>: it's not found as __main__.create_dummy_model_files.<locals>.DummyCarPriceModel"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def create_car_price_csv():\n",
    "    \"\"\"Create car_price.csv with synthetic data\"\"\"\n",
    "    print(\"Creating car_price.csv...\")\n",
    "    np.random.seed(42)\n",
    "    n_samples = 5000\n",
    "    \n",
    "    # Car data\n",
    "    brands_tier1 = ['Tesla', 'Mercedes', 'BMW', 'Audi', 'Porsche']\n",
    "    brands_tier2 = ['Lexus', 'Volvo', 'Jaguar', 'Land Rover']\n",
    "    brands_tier3 = ['Toyota', 'Honda', 'Ford', 'Chevrolet', 'Nissan', 'Hyundai', 'Kia']\n",
    "    all_brands = brands_tier1 + brands_tier2 + brands_tier3\n",
    "    \n",
    "    data = {\n",
    "        'car_id': range(1, n_samples + 1),\n",
    "        'brand': np.random.choice(all_brands, n_samples),\n",
    "        'model': np.random.choice(['Sedan', 'SUV', 'Truck', 'Coupe', 'Convertible', 'Hatchback', 'Minivan'], n_samples),\n",
    "        'year': np.random.randint(2000, 2024, n_samples),\n",
    "        'mileage': np.random.exponential(50000, n_samples).astype(int),\n",
    "        'engine_size': np.round(np.random.uniform(1.0, 6.0, n_samples), 1),\n",
    "        'fuel_type': np.random.choice(['Petrol', 'Diesel', 'Hybrid', 'Electric'], n_samples, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "        'transmission': np.random.choice(['Automatic', 'Manual', 'CVT'], n_samples, p=[0.7, 0.25, 0.05]),\n",
    "        'owner_count': np.random.randint(0, 6, n_samples),\n",
    "        'accident_history': np.random.choice([0, 1], n_samples, p=[0.85, 0.15]),\n",
    "        'service_history': np.random.choice(['Full', 'Partial', 'None'], n_samples, p=[0.6, 0.3, 0.1]),\n",
    "        'color': np.random.choice(['Black', 'White', 'Silver', 'Gray', 'Red', 'Blue', 'Green'], n_samples),\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate realistic prices\n",
    "    def calculate_price(row):\n",
    "        price = 20000\n",
    "        \n",
    "        # Brand effect\n",
    "        if row['brand'] in brands_tier1:\n",
    "            price *= 2.5\n",
    "        elif row['brand'] in brands_tier2:\n",
    "            price *= 1.8\n",
    "        \n",
    "        # Model effect\n",
    "        model_mult = {\n",
    "            'SUV': 1.3, 'Truck': 1.2, 'Coupe': 1.1,\n",
    "            'Convertible': 1.4, 'Sedan': 1.0,\n",
    "            'Hatchback': 0.9, 'Minivan': 0.95\n",
    "        }.get(row['model'], 1.0)\n",
    "        price *= model_mult\n",
    "        \n",
    "        # Year effect\n",
    "        price += (row['year'] - 2000) * 800\n",
    "        \n",
    "        # Mileage effect\n",
    "        price -= row['mileage'] * 0.08\n",
    "        \n",
    "        # Engine size\n",
    "        price += row['engine_size'] * 1500\n",
    "        \n",
    "        # Fuel type\n",
    "        if row['fuel_type'] == 'Electric':\n",
    "            price += 15000\n",
    "        elif row['fuel_type'] == 'Hybrid':\n",
    "            price += 8000\n",
    "        elif row['fuel_type'] == 'Diesel':\n",
    "            price += 3000\n",
    "        \n",
    "        # Transmission\n",
    "        if row['transmission'] == 'Manual':\n",
    "            price -= 2000\n",
    "        elif row['transmission'] == 'CVT':\n",
    "            price += 1000\n",
    "        \n",
    "        # Owners\n",
    "        price -= row['owner_count'] * 1500\n",
    "        \n",
    "        # Accidents\n",
    "        if row['accident_history'] == 1:\n",
    "            price *= 0.65\n",
    "        \n",
    "        # Service history\n",
    "        if row['service_history'] == 'Partial':\n",
    "            price *= 0.9\n",
    "        elif row['service_history'] == 'None':\n",
    "            price *= 0.7\n",
    "        \n",
    "        # Random variation\n",
    "        price += np.random.normal(0, 5000)\n",
    "        \n",
    "        return max(price, 3000)\n",
    "    \n",
    "    df['price'] = df.apply(calculate_price, axis=1).round(2)\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv('car_price.csv', index=False)\n",
    "    print(f\"✓ Created car_price.csv with {n_samples} records\")\n",
    "    print(f\"  Price range: ${df['price'].min():,.2f} to ${df['price'].max():,.2f}\")\n",
    "    return df\n",
    "\n",
    "def create_dummy_model_files():\n",
    "    \"\"\"Create dummy model files for immediate use\"\"\"\n",
    "    print(\"\\nCreating model files...\")\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    \n",
    "    # Create a simple preprocessing info structure\n",
    "    preprocessing_info = {\n",
    "        'categorical_features': ['brand', 'model', 'fuel_type', 'transmission', 'service_history'],\n",
    "        'numerical_features': ['year', 'mileage', 'engine_size', 'owner_count', 'accident_history'],\n",
    "        'all_features': ['brand', 'model', 'year', 'mileage', 'engine_size', \n",
    "                        'fuel_type', 'transmission', 'owner_count', \n",
    "                        'accident_history', 'service_history'],\n",
    "        'categorical_categories': {\n",
    "            'brand': ['Toyota', 'Honda', 'Ford', 'BMW', 'Mercedes', 'Audi', \n",
    "                     'Hyundai', 'Tesla', 'Chevrolet', 'Nissan', 'Kia', \n",
    "                     'Lexus', 'Volvo', 'Jaguar', 'Land Rover', 'Porsche'],\n",
    "            'model': ['Sedan', 'SUV', 'Truck', 'Coupe', 'Convertible', 'Hatchback', 'Minivan'],\n",
    "            'fuel_type': ['Petrol', 'Diesel', 'Hybrid', 'Electric'],\n",
    "            'transmission': ['Automatic', 'Manual', 'CVT'],\n",
    "            'service_history': ['Full', 'Partial', 'None']\n",
    "        },\n",
    "        'numerical_stats': {\n",
    "            'year': {'min': 2000, 'max': 2023, 'mean': 2015.5, 'std': 4.5},\n",
    "            'mileage': {'min': 1000, 'max': 250000, 'mean': 75000, 'std': 40000},\n",
    "            'engine_size': {'min': 1.0, 'max': 6.0, 'mean': 2.5, 'std': 1.0},\n",
    "            'owner_count': {'min': 0, 'max': 5, 'mean': 1.5, 'std': 1.2},\n",
    "            'accident_history': {'min': 0, 'max': 1, 'mean': 0.15, 'std': 0.36}\n",
    "        },\n",
    "        'price_stats': {\n",
    "            'min': 3000,\n",
    "            'max': 120000,\n",
    "            'mean': 35000,\n",
    "            'std': 20000\n",
    "        },\n",
    "        'model_metadata': {\n",
    "            'model_type': 'DummyModel',\n",
    "            'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'description': 'Placeholder model - run train_model.py to train actual model'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save preprocessing info\n",
    "    joblib.dump(preprocessing_info, 'model/preprocessing.pkl')\n",
    "    \n",
    "    # Create a dummy model class\n",
    "    class DummyCarPriceModel:\n",
    "        def predict(self, X):\n",
    "            \"\"\"Simple linear formula for price prediction\"\"\"\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                # Extract features\n",
    "                predictions = []\n",
    "                for _, row in X.iterrows():\n",
    "                    price = 20000\n",
    "                    \n",
    "                    # Simple calculations\n",
    "                    if row['brand'] in ['BMW', 'Mercedes', 'Audi', 'Tesla', 'Porsche']:\n",
    "                        price *= 1.8\n",
    "                    elif row['brand'] in ['Lexus', 'Volvo', 'Jaguar', 'Land Rover']:\n",
    "                        price *= 1.4\n",
    "                    \n",
    "                    price += (row['year'] - 2000) * 800\n",
    "                    price -= row['mileage'] * 0.1\n",
    "                    price += row['engine_size'] * 2000\n",
    "                    \n",
    "                    if row['fuel_type'] == 'Electric':\n",
    "                        price += 12000\n",
    "                    elif row['fuel_type'] == 'Hybrid':\n",
    "                        price += 6000\n",
    "                    \n",
    "                    if row['transmission'] == 'Manual':\n",
    "                        price -= 1500\n",
    "                    \n",
    "                    price -= row['owner_count'] * 1000\n",
    "                    \n",
    "                    if row['accident_history'] == 1:\n",
    "                        price *= 0.7\n",
    "                    \n",
    "                    predictions.append(price)\n",
    "                \n",
    "                return np.array(predictions)\n",
    "            return np.array([35000])  # Default price\n",
    "    \n",
    "    # Create and save dummy model\n",
    "    dummy_model = {\n",
    "        'model': DummyCarPriceModel(),\n",
    "        'preprocessor': None,\n",
    "        '_is_fitted': True\n",
    "    }\n",
    "    \n",
    "    joblib.dump(dummy_model, 'model/car_price_model.pkl')\n",
    "    \n",
    "    print(\"✓ Created dummy model files\")\n",
    "    print(\"⚠️  Note: These are placeholder files. Run train_model.py for actual trained model.\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to create all files\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"CAR PRICE PREDICTION PROJECT - FILE GENERATOR\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create CSV file\n",
    "    df = create_car_price_csv()\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    \n",
    "    # Create dummy model files for immediate use\n",
    "    create_dummy_model_files()\n",
    "    \n",
    "    # Create a simple train_model.py that users can run\n",
    "    create_train_script()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ALL FILES CREATED SUCCESSFULLY!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nFiles created:\")\n",
    "    print(\"1. car_price.csv - Dataset with 5,000 car records\")\n",
    "    print(\"2. model/car_price_model.pkl - Placeholder model file\")\n",
    "    print(\"3. model/preprocessing.pkl - Feature information\")\n",
    "    print(\"4. train_model.py - Script to train actual model\")\n",
    "    \n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Install requirements: pip install -r requirements.txt\")\n",
    "    print(\"2. Train the model: python train_model.py\")\n",
    "    print(\"3. Run the app: streamlit run app.py\")\n",
    "\n",
    "def create_train_script():\n",
    "    \"\"\"Create a train_model.py script\"\"\"\n",
    "    train_script = '''import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('car_price.csv')\n",
    "df = df.drop(['car_id', 'color'], axis=1)\n",
    "\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "categorical_features = ['brand', 'model', 'fuel_type', 'transmission', 'service_history']\n",
    "numerical_features = ['year', 'mileage', 'engine_size', 'owner_count', 'accident_history']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\\\nModel Performance:\")\n",
    "print(f\"MAE: ${mae:,.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "os.makedirs('model', exist_ok=True)\n",
    "joblib.dump(model, 'model/car_price_model.pkl')\n",
    "\n",
    "feature_info = {\n",
    "    'categorical_features': categorical_features,\n",
    "    'numerical_features': numerical_features,\n",
    "    'all_features': list(X.columns)\n",
    "}\n",
    "joblib.dump(feature_info, 'model/preprocessing.pkl')\n",
    "\n",
    "print(\"\\\\nModel saved successfully!\")\n",
    "'''\n",
    "    \n",
    "    with open('train_model.py', 'w') as f:\n",
    "        f.write(train_script)\n",
    "    print(\"✓ Created train_model.py\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2faa3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
